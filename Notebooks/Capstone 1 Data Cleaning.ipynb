{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Source data from Kaggle\n",
    "\n",
    "Import and clean IPO Data\n",
    "Data set has 3,762 rows, each row representing the IPO company\n",
    "Over 1,600 columns\n",
    "The file contains the open, close, low, high, and volume for the 261 trading days following the IPO. (1,305 data points). This data is listed inefficiently in the columns.\n",
    "\n",
    "First step of data cleaning will be to use the source data to create two tables\n",
    "    1. A pricing table simply listing the stock ticker and trading day as attribute columns. Stock open, close, low, high, and volume will be listed as the values\n",
    "    2. An attribute table containing metadata on the stock ticker. I.e. company name, date founded, IPO date, CEO, headquartered location, etc. (all of these data points are on the source file as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('C:\\\\Users\\\\nmur1\\\\Google Drive\\\\Springboard\\\\Capstone 1\\\\SourceData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3762, 1664)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "sourcepath = r'C:\\Users\\nmur1\\Google Drive\\Springboard\\Capstone 1\\SourceData'\n",
    "\n",
    "#import raw data as RawDF\n",
    "RawDF = pd.read_csv('IPO Data.csv',low_memory = False, encoding='ISO-8859-1')\n",
    "\n",
    "#break off stockticker and pricing data\n",
    "Pricing = RawDF.iloc[:,0:1319]\n",
    "Pricing = Pricing.drop(Pricing.columns[1:9], axis = 1)\n",
    "\n",
    "#Reindex to symbol \n",
    "Pricing = Pricing.set_index('Symbol')\n",
    "\n",
    "#add Ipo date to dateframe\n",
    "IPO_Date = RawDF.loc[:,['Symbol','ipoDate']].set_index('Symbol')\n",
    "IPO_Date['ipoDate'] = pd.to_datetime(IPO_Date['ipoDate'])\n",
    "Pricing = pd.concat([Pricing,IPO_Date], axis = 1)\n",
    "\n",
    "#after inspection I foudn that MITT repeated 64 times. Drop the duplicates here\n",
    "Pricing = Pricing.drop_duplicates()\n",
    "RawDF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull out daily pricing from the columns to make a Pricing Table\n",
    "The next sub routine will loop through the pricing dataframe established above and create a new dataframe with the Symbol, Trading Day, Open, Closing, Low, High, and Volume as the column. Row will represent the values for a stock on the given trading day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Trade Day</th>\n",
       "      <th>C</th>\n",
       "      <th>H</th>\n",
       "      <th>O</th>\n",
       "      <th>L</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>28.6358</td>\n",
       "      <td>33.5207</td>\n",
       "      <td>27.3725</td>\n",
       "      <td>30.6572</td>\n",
       "      <td>59753154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAC</td>\n",
       "      <td>0</td>\n",
       "      <td>18.5000</td>\n",
       "      <td>20.1000</td>\n",
       "      <td>17.6000</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>2799073.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAOI</td>\n",
       "      <td>0</td>\n",
       "      <td>9.9600</td>\n",
       "      <td>10.0900</td>\n",
       "      <td>9.3700</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>948999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAP</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9000</td>\n",
       "      <td>14.4667</td>\n",
       "      <td>13.3833</td>\n",
       "      <td>13.4000</td>\n",
       "      <td>371100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAT</td>\n",
       "      <td>0</td>\n",
       "      <td>21.2500</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>21.1800</td>\n",
       "      <td>21.5300</td>\n",
       "      <td>15536889.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968603</th>\n",
       "      <td>ZNH</td>\n",
       "      <td>261</td>\n",
       "      <td>3.9587</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>3.8753</td>\n",
       "      <td>3.8753</td>\n",
       "      <td>98700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968606</th>\n",
       "      <td>ZSAN</td>\n",
       "      <td>261</td>\n",
       "      <td>45.6000</td>\n",
       "      <td>45.6000</td>\n",
       "      <td>42.8000</td>\n",
       "      <td>42.8000</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968607</th>\n",
       "      <td>ZTO</td>\n",
       "      <td>261</td>\n",
       "      <td>15.7300</td>\n",
       "      <td>15.8950</td>\n",
       "      <td>15.3500</td>\n",
       "      <td>15.6000</td>\n",
       "      <td>1922801.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968611</th>\n",
       "      <td>ZX</td>\n",
       "      <td>261</td>\n",
       "      <td>3.4600</td>\n",
       "      <td>3.5500</td>\n",
       "      <td>3.3600</td>\n",
       "      <td>3.5300</td>\n",
       "      <td>22850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968613</th>\n",
       "      <td>ZYNE</td>\n",
       "      <td>261</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>9.5100</td>\n",
       "      <td>364559.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>907446 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Symbol  Trade Day        C        H        O        L           V\n",
       "0           A          0  28.6358  33.5207  27.3725  30.6572  59753154.0\n",
       "1         AAC          0  18.5000  20.1000  17.6000  20.0000   2799073.0\n",
       "2        AAOI          0   9.9600  10.0900   9.3700  10.0000    948999.0\n",
       "3         AAP          0  13.9000  14.4667  13.3833  13.4000    371100.0\n",
       "4         AAT          0  21.2500  22.0000  21.1800  21.5300  15536889.0\n",
       "...       ...        ...      ...      ...      ...      ...         ...\n",
       "968603    ZNH        261   3.9587   4.0000   3.8753   3.8753     98700.0\n",
       "968606   ZSAN        261  45.6000  45.6000  42.8000  42.8000        21.0\n",
       "968607    ZTO        261  15.7300  15.8950  15.3500  15.6000   1922801.0\n",
       "968611     ZX        261   3.4600   3.5500   3.3600   3.5300     22850.0\n",
       "968613   ZYNE        261  10.5000  10.5000   9.5000   9.5100    364559.0\n",
       "\n",
       "[907446 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "#need to clean data and create a new talbe with ticker, trading day, open price, close price, high, low, and volume\n",
    "#in columns with the values for in the rows\n",
    "\n",
    "#create empty lists for my columns\n",
    "tday = []\n",
    "Closing = []\n",
    "High = []\n",
    "Opening = []\n",
    "Low = []\n",
    "Volume = []\n",
    "tday = []\n",
    "\n",
    "cols = 0\n",
    "day = 0\n",
    "\n",
    "#loop through each column of the dataframe to store the pertenint data\n",
    "while cols <= 1305:\n",
    "    \n",
    "    df = pd.DataFrame(Pricing.index)\n",
    "    df['trade day'] = day\n",
    "    tday.append(df)\n",
    "    Closing.append(Pricing.iloc[:,cols]) #closing price starts at 0\n",
    "    High.append(Pricing.iloc[:,cols+1]) #high one column over from closing\n",
    "    Opening.append(Pricing.iloc[:,cols+2]) #opening two columns over from closing\n",
    "    Low.append(Pricing.iloc[:,cols+3]) # low 3 columns over from closing\n",
    "    Volume.append(Pricing.iloc[:,cols+4]) #Volume 3 columns over\n",
    "    \n",
    "    day = day + 1\n",
    "    cols = cols + 5 #increment column by 5 (new day is every 5 columns)\n",
    "\n",
    "#run concatenations on the indexes, to turn into dataframes     \n",
    "df_Closing = pd.concat(Closing, axis = 0).reset_index()\n",
    "df_Closing = df_Closing.drop(df_Closing.columns[0], axis = 1)\n",
    "\n",
    "df_High = pd.concat(High, axis = 0).reset_index()\n",
    "df_High = df_High.drop(df_High.columns[0], axis = 1)\n",
    "\n",
    "df_Opening = pd.concat(Opening, axis = 0).reset_index()\n",
    "df_Opening = df_Opening.drop(df_Opening.columns[0], axis = 1)\n",
    "\n",
    "df_Low = pd.concat(Low, axis = 0).reset_index()\n",
    "df_Low = df_Low.drop(df_Low.columns[0], axis = 1)\n",
    "\n",
    "df_Volume = pd.concat(Volume, axis = 0).reset_index()\n",
    "df_Volume = df_Volume.drop(df_Volume.columns[0], axis = 1)\n",
    "\n",
    "df_Day = pd.concat(tday, axis = 0).reset_index()\n",
    "df_Day = df_Day.drop(df_Day.columns[0], axis = 1)\n",
    "\n",
    "#concatenate all the above dataframes vertically\n",
    "df_pricing = pd.concat([df_Day, df_Closing, df_High, df_Opening, df_Low, df_Volume], axis = 1)\n",
    "df_pricing.columns = ['Symbol', 'Trade Day', 'C', 'H', 'O', 'L', 'V']\n",
    "\n",
    "#inspect new dataframe\n",
    "#should have 261 records for each ticker (1 for each trading day)\n",
    "#drop na's or records that don't have any pricing data\n",
    "df_pricing.dropna(inplace = True)\n",
    "df_pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save CleanData set to new folder\n",
    "os.chdir('C:\\\\Users\\\\nmur1\\\\Google Drive\\\\Springboard\\\\Capstone 1\\\\CleanData')\n",
    "df_pricing.to_csv('DailyPricing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Attribute Table with Key MetaData Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My next step will be to create an attribute or metadata table containing all of the key stats on the stock company. There will be a record/row for each stock with multiple data points including date founded, revenue, income, ipoDate, day of week IPO'd, State, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3762, 354)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make my attribute table with the other metadata\n",
    "#metadata is in columns 0 through 9 and all columns from 1319 to the end of the dataset. \n",
    "#the columns in the middle were pricing data points that I split off into the pricing table listed above\n",
    "\n",
    "#split out desired columns using iloc. Concatenate back to one and inspect:\n",
    "Attribute1 = RawDF.iloc[:,0:9]\n",
    "Attribute2 = RawDF.iloc[:,1319:]\n",
    "FullAttribute = pd.concat([Attribute1,Attribute2], axis = 1)\n",
    "FullAttribute.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce Size of Metadata table by dropping irrelevant columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After analysis my Attribute table still had 354 columns which was quite cumbersome. I reviewed the columns and found that the majority had N/A. To start the below code will identify columsn and % of N/A values. To start I'm only going to keep attributes with less than 50% N/A values. This leaves 50 columns wiht most of the key metadata I'm looking for. I.e. IPO date, CEO age/gender, company location, company age at IPO, year founded etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3762, 50)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create df with N/A percentages\n",
    "nas=pd.DataFrame(FullAttribute.isnull().sum().sort_values(ascending=True)/len(FullAttribute),columns = ['percent'])\n",
    "\n",
    "#filter percent less than 50\n",
    "nasFilt = nas['percent']<=.5\n",
    "\n",
    "#create and apply boolean series filter\n",
    "tokeep = nas[nasFilt]\n",
    "df_Att =FullAttribute.loc[:,tokeep.index]\n",
    "\n",
    "#inspect data\n",
    "df_Att.to_clipboard()\n",
    "df_Att.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the Data I Dropped to Determine if I want to Source Elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Other_intangiblesYearBeforeIPO</th>\n",
       "      <td>0.999734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loans_issuedYearBeforeIPO</th>\n",
       "      <td>0.999734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Preferred_dividendsYearBeforeIPO</th>\n",
       "      <td>0.999734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Restricted_cash_and_cash_equivalentsYearBeforeIPO</th>\n",
       "      <td>0.999734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Provision_for_loan_lossesYearBeforeIPO</th>\n",
       "      <td>0.999734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Net_cash_provided_by_operating_activitiesYearBeforeIPO</th>\n",
       "      <td>0.891015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Net_incomeYearBeforeIPO</th>\n",
       "      <td>0.876396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiscal_year_ends_in_December_USDYearBeforeIPO</th>\n",
       "      <td>0.865231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exactDiffernce</th>\n",
       "      <td>0.583200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lastFiscalYearGrowth</th>\n",
       "      <td>0.508772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     percent\n",
       "Other_intangiblesYearBeforeIPO                      0.999734\n",
       "Loans_issuedYearBeforeIPO                           0.999734\n",
       "Preferred_dividendsYearBeforeIPO                    0.999734\n",
       "Restricted_cash_and_cash_equivalentsYearBeforeIPO   0.999734\n",
       "Provision_for_loan_lossesYearBeforeIPO              0.999734\n",
       "...                                                      ...\n",
       "Net_cash_provided_by_operating_activitiesYearBe...  0.891015\n",
       "Net_incomeYearBeforeIPO                             0.876396\n",
       "Fiscal_year_ends_in_December_USDYearBeforeIPO       0.865231\n",
       "exactDiffernce                                      0.583200\n",
       " lastFiscalYearGrowth                               0.508772\n",
       "\n",
       "[304 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NullColumns =pd.DataFrame(FullAttribute.isnull().sum().sort_values(ascending=False)/len(FullAttribute),columns = ['percent'])\n",
    "NullFilt = NullColumns['percent']>.50\n",
    "\n",
    "NullColumns[NullFilt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the number of unique values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol                        3699\n",
       "Safe                             2\n",
       "Profitable                       2\n",
       "yearDifferenceGrouped            1\n",
       "FoundingDateGrouped              6\n",
       "usablePresidentGender            8\n",
       "usableCEOGender                  8\n",
       "FiscalMonth                     13\n",
       "USACompany                       3\n",
       "MarketYearTrend               2144\n",
       "Market6MonthTrend             2144\n",
       "Market3MonthTrend             2144\n",
       "MarketMonthTrend              2144\n",
       "ipoDate                       2239\n",
       "Summary Quote                 3700\n",
       "HomeRun                          2\n",
       "Month                           12\n",
       "MarketCap                     3552\n",
       "Name                          3556\n",
       "dayOfWeek                        5\n",
       "Day                             31\n",
       "Year                            23\n",
       "daysProfitGrouped                5\n",
       "daysProfit                     263\n",
       "DaysBetterThanSP               153\n",
       "LastSale                      2756\n",
       "usablePresidentAge               8\n",
       "usableCEOAge                     8\n",
       "CEOGender                        6\n",
       "CEOName                       2894\n",
       "Industry                       132\n",
       "Sector                          12\n",
       "PresidentGender                  6\n",
       "PresidentName                 2658\n",
       "YearFounded                    154\n",
       "exactDateFounded              1777\n",
       "yearDifference                 166\n",
       "CEOAge                          57\n",
       "CEOInChargeDuringIPO             3\n",
       "employees                     1432\n",
       "employeesGrouped                 7\n",
       "FiscalDateEnd                   26\n",
       "City                           904\n",
       "stateCountry                    97\n",
       "netIncome                     2558\n",
       "CEOTakeOver                     35\n",
       "PresidentAge                    55\n",
       "Revenue                       2188\n",
       "presidentInChargeDuringIPO       3\n",
       "PresidentTakeOver               33\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Att.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender contains 8 values - need to fix that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Blank            1971\n",
       "Unknown           855\n",
       "male              763\n",
       "unknown            81\n",
       "female             44\n",
       "mostly_male        21\n",
       "andy               16\n",
       "mostly_female      11\n",
       "Name: usableCEOGender, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Att['usableCEOGender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Att['usableCEOGender'] = df_Att['usableCEOGender'].str.replace('Unknown', 'unknown')\n",
    "df_Att['usableCEOGender'] = df_Att['usableCEOGender'].str.replace('Blank', 'unknown')\n",
    "df_Att['usableCEOGender'] = df_Att['usableCEOGender'].str.replace('mostly_male', 'male')\n",
    "df_Att['usableCEOGender'] = df_Att['usableCEOGender'].str.replace('mostly_female', 'female')\n",
    "df_Att['usableCEOGender'] = df_Att['usableCEOGender'].str.replace('andy', 'male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    2907\n",
       "male        800\n",
       "female       55\n",
       "Name: usableCEOGender, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Att['usableCEOGender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CEOGender field looks to contain more relevant data then usableCEOGender\n",
    "\n",
    "df_Att.drop(columns = 'usableCEOGender',inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixed misidentified genders in other CEO Gender column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male             2683\n",
       "unknown           283\n",
       "female            155\n",
       "mostly_male        57\n",
       "andy               51\n",
       "mostly_female      34\n",
       "Name: CEOGender, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Att['CEOGender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male       2791\n",
       "unknown     283\n",
       "female      189\n",
       "Name: CEOGender, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Att['CEOGender'] = df_Att['CEOGender'].str.replace('Unknown', 'unknown')\n",
    "df_Att['CEOGender'] = df_Att['CEOGender'].str.replace('Blank', 'unknown')\n",
    "df_Att['CEOGender'] = df_Att['CEOGender'].str.replace('mostly_male', 'male')\n",
    "df_Att['CEOGender'] = df_Att['CEOGender'].str.replace('mostly_female', 'female')\n",
    "df_Att['CEOGender'] = df_Att['CEOGender'].str.replace('andy', 'male')\n",
    "df_Att['CEOGender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Other Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol               3699\n",
       "Profitable              2\n",
       "FiscalMonth            13\n",
       "USACompany              3\n",
       "MarketYearTrend      2144\n",
       "Market6MonthTrend    2144\n",
       "Market3MonthTrend    2144\n",
       "MarketMonthTrend     2144\n",
       "ipoDate              2239\n",
       "Summary Quote        3700\n",
       "Month                  12\n",
       "MarketCap            3552\n",
       "Name                 3556\n",
       "dayOfWeek               5\n",
       "Day                    31\n",
       "Year                   23\n",
       "LastSale             2756\n",
       "CEOGender               3\n",
       "CEOName              2894\n",
       "Industry              132\n",
       "Sector                 12\n",
       "YearFounded           154\n",
       "exactDateFounded     1777\n",
       "yearDifference        166\n",
       "CEOAge                 57\n",
       "employees            1432\n",
       "employeesGrouped        7\n",
       "FiscalDateEnd          26\n",
       "City                  904\n",
       "stateCountry           97\n",
       "netIncome            2558\n",
       "Revenue              2188\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todrop = ['usablePresidentGender', 'PresidentGender', 'usablePresidentAge', 'HomeRun', 'usableCEOAge','PresidentName','CEOInChargeDuringIPO','CEOTakeOver',\n",
    "             'PresidentAge','presidentInChargeDuringIPO','PresidentTakeOver','Safe','yearDifferenceGrouped', 'daysProfitGrouped',\n",
    "                'daysProfit', 'DaysBetterThanSP', 'FoundingDateGrouped' ]\n",
    "\n",
    "for d in todrop:\n",
    "    \n",
    "    try:\n",
    "        df_Att.drop(columns = d, inplace = True)\n",
    "    except:\n",
    "        df_Att\n",
    "\n",
    "df_Att.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After significantly paring down my attribute table I reviewed all of the fields that were greater than 50% N/A to see if there's anything I wanted to keep. Most are key financila metrics for the company pre-IPO. My hypothesis is that these metrics would have an impact on pricing performance so I will need to find another datasource to pull those metrics in. For purposes of this exercise I'm not going to pull in all 304 rows but we'll start with the big ones:\n",
    "\n",
    "Pre IPO Revenue ||\n",
    "Pre IPO EBIDTA ||\n",
    "Pre IPO Cash ||\n",
    "\n",
    "I don't have a datasource for those yet so let's clean up the table we have and add a few functions in the next two steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Additional Conversion Functions to Clean Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define fiscal quarter based on input date\n",
    "\n",
    "def FQ(date):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        if date.month in range(0,4):\n",
    "            return '1_' + str(date.year)\n",
    "        elif date.month in range(4,7):\n",
    "            return '2_' + str(date.year)\n",
    "        elif date.month in range(7,10):\n",
    "            return '3_' + str(date.year)\n",
    "        elif date.month in range(10,13):\n",
    "            return '4_'+ str(date.year)\n",
    "        else:\n",
    "            return 'NA'\n",
    "    except:\n",
    "       \n",
    "        return \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Profitable</th>\n",
       "      <th>FiscalMonth</th>\n",
       "      <th>USACompany</th>\n",
       "      <th>MarketYearTrend</th>\n",
       "      <th>Market6MonthTrend</th>\n",
       "      <th>Market3MonthTrend</th>\n",
       "      <th>MarketMonthTrend</th>\n",
       "      <th>ipoDate</th>\n",
       "      <th>Summary Quote</th>\n",
       "      <th>...</th>\n",
       "      <th>City</th>\n",
       "      <th>stateCountry</th>\n",
       "      <th>netIncome</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Country</th>\n",
       "      <th>Revenue_M</th>\n",
       "      <th>Income_M</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>AgeatIPO</th>\n",
       "      <th>FQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>Oct</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.039844</td>\n",
       "      <td>2.312974</td>\n",
       "      <td>2.352508</td>\n",
       "      <td>1.601165</td>\n",
       "      <td>1999-11-18</td>\n",
       "      <td>https://www.nasdaq.com/symbol/a</td>\n",
       "      <td>...</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>CA</td>\n",
       "      <td>$684.00M</td>\n",
       "      <td>$4.47B</td>\n",
       "      <td>US</td>\n",
       "      <td>4470.00</td>\n",
       "      <td>684.00</td>\n",
       "      <td>Thur</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4_1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAC</td>\n",
       "      <td>1</td>\n",
       "      <td>Dec</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.881839</td>\n",
       "      <td>0.138536</td>\n",
       "      <td>-1.194498</td>\n",
       "      <td>-2.452645</td>\n",
       "      <td>2014-10-02</td>\n",
       "      <td>https://www.nasdaq.com/symbol/aac</td>\n",
       "      <td>...</td>\n",
       "      <td>Brentwood</td>\n",
       "      <td>TN</td>\n",
       "      <td>$-20.58M</td>\n",
       "      <td>$317.64M</td>\n",
       "      <td>US</td>\n",
       "      <td>317.64</td>\n",
       "      <td>-20.58</td>\n",
       "      <td>Thur</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4_2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAOI</td>\n",
       "      <td>1</td>\n",
       "      <td>Dec</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.443672</td>\n",
       "      <td>1.286165</td>\n",
       "      <td>0.926398</td>\n",
       "      <td>0.761732</td>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>https://www.nasdaq.com/symbol/aaoi</td>\n",
       "      <td>...</td>\n",
       "      <td>Sugar Land</td>\n",
       "      <td>TX</td>\n",
       "      <td>$73.95M</td>\n",
       "      <td>$382.33M</td>\n",
       "      <td>US</td>\n",
       "      <td>382.33</td>\n",
       "      <td>73.95</td>\n",
       "      <td>Thur</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3_2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAP</td>\n",
       "      <td>1</td>\n",
       "      <td>Dec</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.745906</td>\n",
       "      <td>-0.128110</td>\n",
       "      <td>1.153716</td>\n",
       "      <td>0.613550</td>\n",
       "      <td>2001-11-29</td>\n",
       "      <td>https://www.nasdaq.com/symbol/aap</td>\n",
       "      <td>...</td>\n",
       "      <td>Roanoke</td>\n",
       "      <td>VA</td>\n",
       "      <td>$475.51M</td>\n",
       "      <td>$9.37B</td>\n",
       "      <td>US</td>\n",
       "      <td>9370.00</td>\n",
       "      <td>475.51</td>\n",
       "      <td>Thur</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4_2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAT</td>\n",
       "      <td>0</td>\n",
       "      <td>Dec</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.263666</td>\n",
       "      <td>1.813736</td>\n",
       "      <td>1.824305</td>\n",
       "      <td>1.692499</td>\n",
       "      <td>2011-01-13</td>\n",
       "      <td>https://www.nasdaq.com/symbol/aat</td>\n",
       "      <td>...</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>CA</td>\n",
       "      <td>$29.08M</td>\n",
       "      <td>$311.68M</td>\n",
       "      <td>US</td>\n",
       "      <td>311.68</td>\n",
       "      <td>29.08</td>\n",
       "      <td>Thur</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1_2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3754</th>\n",
       "      <td>ZSAN</td>\n",
       "      <td>0</td>\n",
       "      <td>Dec</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.055378</td>\n",
       "      <td>0.515719</td>\n",
       "      <td>-0.448387</td>\n",
       "      <td>-0.373177</td>\n",
       "      <td>2015-01-27</td>\n",
       "      <td>https://www.nasdaq.com/symbol/zsan</td>\n",
       "      <td>...</td>\n",
       "      <td>Fremont</td>\n",
       "      <td>CA</td>\n",
       "      <td>$-29.11M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-29.11</td>\n",
       "      <td>Tue</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1_2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>1</td>\n",
       "      <td>Dec</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.456595</td>\n",
       "      <td>2.497749</td>\n",
       "      <td>1.941604</td>\n",
       "      <td>1.830451</td>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>https://www.nasdaq.com/symbol/zts</td>\n",
       "      <td>...</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>$864.00M</td>\n",
       "      <td>$5.31B</td>\n",
       "      <td>US</td>\n",
       "      <td>5310.00</td>\n",
       "      <td>864.00</td>\n",
       "      <td>Fri</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1_2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>ZUMZ</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.546793</td>\n",
       "      <td>-0.792605</td>\n",
       "      <td>-0.612410</td>\n",
       "      <td>0.510960</td>\n",
       "      <td>2005-05-06</td>\n",
       "      <td>https://www.nasdaq.com/symbol/zumz</td>\n",
       "      <td>...</td>\n",
       "      <td>Lynnwood</td>\n",
       "      <td>WA</td>\n",
       "      <td>$26.80M</td>\n",
       "      <td>$927.40M</td>\n",
       "      <td>US</td>\n",
       "      <td>927.40</td>\n",
       "      <td>26.80</td>\n",
       "      <td>Fri</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2_2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>ZUO</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.794603</td>\n",
       "      <td>-0.113986</td>\n",
       "      <td>-0.734112</td>\n",
       "      <td>0.031797</td>\n",
       "      <td>2018-04-12</td>\n",
       "      <td>https://www.nasdaq.com/symbol/zuo</td>\n",
       "      <td>...</td>\n",
       "      <td>Redwood City</td>\n",
       "      <td>CA</td>\n",
       "      <td>$-47.16M</td>\n",
       "      <td>$167.93M</td>\n",
       "      <td>US</td>\n",
       "      <td>167.93</td>\n",
       "      <td>-47.16</td>\n",
       "      <td>Thur</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2_2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>ZYNE</td>\n",
       "      <td>0</td>\n",
       "      <td>Dec</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.835617</td>\n",
       "      <td>0.239617</td>\n",
       "      <td>-0.064559</td>\n",
       "      <td>0.173427</td>\n",
       "      <td>2015-08-05</td>\n",
       "      <td>https://www.nasdaq.com/symbol/zyne</td>\n",
       "      <td>...</td>\n",
       "      <td>Devon</td>\n",
       "      <td>PA</td>\n",
       "      <td>$-32.01M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-32.01</td>\n",
       "      <td>Wed</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3_2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2312 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Symbol  Profitable FiscalMonth USACompany  MarketYearTrend  \\\n",
       "0         A           1         Oct        Yes         2.039844   \n",
       "1       AAC           1         Dec        Yes         0.881839   \n",
       "2      AAOI           1         Dec        Yes         1.443672   \n",
       "3       AAP           1         Dec        Yes        -0.745906   \n",
       "4       AAT           0         Dec        Yes         2.263666   \n",
       "...     ...         ...         ...        ...              ...   \n",
       "3754   ZSAN           0         Dec        Yes         1.055378   \n",
       "3756    ZTS           1         Dec        Yes         2.456595   \n",
       "3757   ZUMZ           1         Jan        Yes         0.546793   \n",
       "3758    ZUO           0         Jan        Yes         0.794603   \n",
       "3761   ZYNE           0         Dec        Yes         0.835617   \n",
       "\n",
       "      Market6MonthTrend  Market3MonthTrend  MarketMonthTrend    ipoDate  \\\n",
       "0              2.312974           2.352508          1.601165 1999-11-18   \n",
       "1              0.138536          -1.194498         -2.452645 2014-10-02   \n",
       "2              1.286165           0.926398          0.761732 2013-09-26   \n",
       "3             -0.128110           1.153716          0.613550 2001-11-29   \n",
       "4              1.813736           1.824305          1.692499 2011-01-13   \n",
       "...                 ...                ...               ...        ...   \n",
       "3754           0.515719          -0.448387         -0.373177 2015-01-27   \n",
       "3756           2.497749           1.941604          1.830451 2013-02-01   \n",
       "3757          -0.792605          -0.612410          0.510960 2005-05-06   \n",
       "3758          -0.113986          -0.734112          0.031797 2018-04-12   \n",
       "3761           0.239617          -0.064559          0.173427 2015-08-05   \n",
       "\n",
       "                           Summary Quote  ...           City  stateCountry  \\\n",
       "0        https://www.nasdaq.com/symbol/a  ...    Santa Clara            CA   \n",
       "1      https://www.nasdaq.com/symbol/aac  ...      Brentwood            TN   \n",
       "2     https://www.nasdaq.com/symbol/aaoi  ...     Sugar Land            TX   \n",
       "3      https://www.nasdaq.com/symbol/aap  ...        Roanoke            VA   \n",
       "4      https://www.nasdaq.com/symbol/aat  ...      San Diego            CA   \n",
       "...                                  ...  ...            ...           ...   \n",
       "3754  https://www.nasdaq.com/symbol/zsan  ...        Fremont            CA   \n",
       "3756   https://www.nasdaq.com/symbol/zts  ...       New York            NY   \n",
       "3757  https://www.nasdaq.com/symbol/zumz  ...       Lynnwood            WA   \n",
       "3758   https://www.nasdaq.com/symbol/zuo  ...   Redwood City            CA   \n",
       "3761  https://www.nasdaq.com/symbol/zyne  ...          Devon            PA   \n",
       "\n",
       "     netIncome   Revenue  Country  Revenue_M  Income_M DayofWeek AgeatIPO  \\\n",
       "0     $684.00M    $4.47B       US    4470.00    684.00      Thur      0.0   \n",
       "1     $-20.58M  $317.64M       US     317.64    -20.58      Thur      0.0   \n",
       "2      $73.95M  $382.33M       US     382.33     73.95      Thur     16.0   \n",
       "3     $475.51M    $9.37B       US    9370.00    475.51      Thur     72.0   \n",
       "4      $29.08M  $311.68M       US     311.68     29.08      Thur      1.0   \n",
       "...        ...       ...      ...        ...       ...       ...      ...   \n",
       "3754  $-29.11M       NaN       US       0.00    -29.11       Tue      3.0   \n",
       "3756  $864.00M    $5.31B       US    5310.00    864.00       Fri      1.0   \n",
       "3757   $26.80M  $927.40M       US     927.40     26.80       Fri     27.0   \n",
       "3758  $-47.16M  $167.93M       US     167.93    -47.16      Thur     11.0   \n",
       "3761  $-32.01M       NaN       US       0.00    -32.01       Wed      8.0   \n",
       "\n",
       "          FQ  \n",
       "0     4_1999  \n",
       "1     4_2014  \n",
       "2     3_2013  \n",
       "3     4_2001  \n",
       "4     1_2011  \n",
       "...      ...  \n",
       "3754  1_2015  \n",
       "3756  1_2013  \n",
       "3757  2_2005  \n",
       "3758  2_2018  \n",
       "3761  3_2015  \n",
       "\n",
       "[2312 rows x 38 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create an attribute table for additional analysis\n",
    "#pd.options.display.float_format = '{:.5f}'.format\n",
    "#define US or Other country\n",
    "def country(x):\n",
    "    \n",
    "    if len(str(x).strip()) == 2:\n",
    "        return 'US'\n",
    "    else:\n",
    "        return 'Other'\n",
    "        \n",
    "#Revenue and Income columns end with 'B' to denote billions, 'M' to denote millions, or have the straight number if\n",
    "# less than 1 million. The below function will stip the last character and convert to a float value that consistently\n",
    "# represents revenue and income has millions. I.e. 1 billion displayed as 1,000; 1 million displayed as 1; 100,000 displayed\n",
    "#as .1\n",
    "\n",
    "def conversion(x):\n",
    "   \n",
    "    s = str(x).strip() #ensure there are no spaces in string\n",
    "\n",
    "    suffix = str(x)[-1] #get last charcter\n",
    "    \n",
    "    if suffix == 'B': #if B define multiple as 1,000\n",
    "        mult = 1000\n",
    "    elif suffix == 'M': #if M define multiple as 1\n",
    "        mult = 1\n",
    "    else:\n",
    "        mult = 0.000001 #if not B or M multiple is 1/1000000\n",
    " \n",
    "    \n",
    "    #loop through stirng and remove non numbers. Mainly $ signs and commas\n",
    "    #noticed that some strings also had typos with parentheticals so \n",
    "    #the below loop ensures that all non numbers except for decimial points and negative symbols\n",
    "    #are removed\n",
    "    \n",
    "    for letter in s:\n",
    "         if letter.isdigit() == False and letter != '.' and letter != \"-\":\n",
    "            s = s.replace(letter,\"\")\n",
    "    \n",
    "    #handle the nulls\n",
    "    if pd.isnull(x) == True:\n",
    "        s = 0\n",
    "    \n",
    "    #convert the final string to a float and multiple by the multiple\n",
    "    return round(float(s) * mult, 3)\n",
    "\n",
    "def DOW(x):\n",
    "\n",
    "    day = ['Mon','Tue','Wed','Thur','Fri','Sat','Sun']\n",
    "    return day[x.weekday()]\n",
    "        \n",
    "\n",
    "df_Att['Country'] = df_Att['stateCountry'].apply(country)\n",
    "df_Att['Revenue_M'] = df_Att['Revenue'].apply(conversion)\n",
    "df_Att['Income_M'] = df_Att['netIncome'].apply(conversion)\n",
    "df_Att.ipoDate = pd.to_datetime(df_Att['ipoDate'])\n",
    "df_Att['DayofWeek'] = df_Att['ipoDate'].apply(DOW) #Add the name of the day ipo'd\n",
    "df_Att = df_Att[df_Att.Country == 'US']# Filter on US\n",
    "df_Att['AgeatIPO'] = df_Att['Year'] - df_Att['YearFounded']\n",
    "\n",
    "df_Att.sort_values('Revenue_M')#sort by revenue\n",
    "df_Att['FQ'] = df_Att['ipoDate'].apply(FQ)\n",
    "\n",
    "df_Att.to_excel('IPO Attributes.xls') #export to excel for review/analysis\n",
    "\n",
    "df_Att\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>ipoDate</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Year</th>\n",
       "      <th>CEOGender</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>CEOAge</th>\n",
       "      <th>employees</th>\n",
       "      <th>Revenue_M</th>\n",
       "      <th>Income_M</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>AgeatIPO</th>\n",
       "      <th>FQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1999-11-18</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>1999</td>\n",
       "      <td>male</td>\n",
       "      <td>Biotechnology: Laboratory Analytical Instruments</td>\n",
       "      <td>Capital Goods</td>\n",
       "      <td>56.0</td>\n",
       "      <td>13500</td>\n",
       "      <td>4470.00</td>\n",
       "      <td>684.00</td>\n",
       "      <td>Thur</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4_1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAC</td>\n",
       "      <td>2014-10-02</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>male</td>\n",
       "      <td>Medical Specialities</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2100</td>\n",
       "      <td>317.64</td>\n",
       "      <td>-20.58</td>\n",
       "      <td>Thur</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4_2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAOI</td>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>2013</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Semiconductors</td>\n",
       "      <td>Technology</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3054</td>\n",
       "      <td>382.33</td>\n",
       "      <td>73.95</td>\n",
       "      <td>Thur</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3_2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAP</td>\n",
       "      <td>2001-11-29</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>2001</td>\n",
       "      <td>male</td>\n",
       "      <td>Other Specialty Stores</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>59.0</td>\n",
       "      <td>71000</td>\n",
       "      <td>9370.00</td>\n",
       "      <td>475.51</td>\n",
       "      <td>Thur</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4_2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAT</td>\n",
       "      <td>2011-01-13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2011</td>\n",
       "      <td>male</td>\n",
       "      <td>Real Estate Investment Trusts</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>79.0</td>\n",
       "      <td>194</td>\n",
       "      <td>311.68</td>\n",
       "      <td>29.08</td>\n",
       "      <td>Thur</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1_2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3754</th>\n",
       "      <td>ZSAN</td>\n",
       "      <td>2015-01-27</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>2015</td>\n",
       "      <td>male</td>\n",
       "      <td>Major Pharmaceuticals</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>68.0</td>\n",
       "      <td>51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-29.11</td>\n",
       "      <td>Tue</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1_2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>male</td>\n",
       "      <td>Major Pharmaceuticals</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9200</td>\n",
       "      <td>5310.00</td>\n",
       "      <td>864.00</td>\n",
       "      <td>Fri</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1_2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>ZUMZ</td>\n",
       "      <td>2005-05-06</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2005</td>\n",
       "      <td>male</td>\n",
       "      <td>Clothing/Shoe/Accessory Stores</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>57.0</td>\n",
       "      <td>8900</td>\n",
       "      <td>927.40</td>\n",
       "      <td>26.80</td>\n",
       "      <td>Fri</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2_2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>ZUO</td>\n",
       "      <td>2018-04-12</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2018</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>933</td>\n",
       "      <td>167.93</td>\n",
       "      <td>-47.16</td>\n",
       "      <td>Thur</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2_2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>ZYNE</td>\n",
       "      <td>2015-08-05</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>male</td>\n",
       "      <td>Major Pharmaceuticals</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>59.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-32.01</td>\n",
       "      <td>Wed</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3_2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2312 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Symbol    ipoDate  Month  Day  Year CEOGender  \\\n",
       "0         A 1999-11-18     11   18  1999      male   \n",
       "1       AAC 2014-10-02     10    2  2014      male   \n",
       "2      AAOI 2013-09-26      9   26  2013   unknown   \n",
       "3       AAP 2001-11-29     11   29  2001      male   \n",
       "4       AAT 2011-01-13      1   13  2011      male   \n",
       "...     ...        ...    ...  ...   ...       ...   \n",
       "3754   ZSAN 2015-01-27      1   27  2015      male   \n",
       "3756    ZTS 2013-02-01      2    1  2013      male   \n",
       "3757   ZUMZ 2005-05-06      5    6  2005      male   \n",
       "3758    ZUO 2018-04-12      4   12  2018      male   \n",
       "3761   ZYNE 2015-08-05      8    5  2015      male   \n",
       "\n",
       "                                              Industry             Sector  \\\n",
       "0     Biotechnology: Laboratory Analytical Instruments      Capital Goods   \n",
       "1                                 Medical Specialities        Health Care   \n",
       "2                                       Semiconductors         Technology   \n",
       "3                               Other Specialty Stores  Consumer Services   \n",
       "4                        Real Estate Investment Trusts  Consumer Services   \n",
       "...                                                ...                ...   \n",
       "3754                             Major Pharmaceuticals        Health Care   \n",
       "3756                             Major Pharmaceuticals        Health Care   \n",
       "3757                    Clothing/Shoe/Accessory Stores  Consumer Services   \n",
       "3758                                               NaN                NaN   \n",
       "3761                             Major Pharmaceuticals        Health Care   \n",
       "\n",
       "      CEOAge employees  Revenue_M  Income_M DayofWeek  AgeatIPO      FQ  \n",
       "0       56.0     13500    4470.00    684.00      Thur       0.0  4_1999  \n",
       "1       46.0      2100     317.64    -20.58      Thur       0.0  4_2014  \n",
       "2       54.0      3054     382.33     73.95      Thur      16.0  3_2013  \n",
       "3       59.0     71000    9370.00    475.51      Thur      72.0  4_2001  \n",
       "4       79.0       194     311.68     29.08      Thur       1.0  1_2011  \n",
       "...      ...       ...        ...       ...       ...       ...     ...  \n",
       "3754    68.0        51       0.00    -29.11       Tue       3.0  1_2015  \n",
       "3756    66.0      9200    5310.00    864.00       Fri       1.0  1_2013  \n",
       "3757    57.0      8900     927.40     26.80       Fri      27.0  2_2005  \n",
       "3758     NaN       933     167.93    -47.16      Thur      11.0  2_2018  \n",
       "3761    59.0        22       0.00    -32.01       Wed       8.0  3_2015  \n",
       "\n",
       "[2312 rows x 15 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop = [ 'Profitable', 'USACompany', 'MarketYearTrend',\n",
    "       'Market6MonthTrend', 'Market3MonthTrend', 'MarketMonthTrend', \n",
    "       'Summary Quote', 'MarketCap',\n",
    "        'LastSale', 'CEOName',\n",
    "       'exactDateFounded', 'yearDifference', \n",
    "        'employeesGrouped', 'FiscalDateEnd', 'City',\n",
    "        'Country', 'FiscalMonth', 'Name', 'dayOfWeek','stateCountry', 'netIncome','Revenue', 'YearFounded']\n",
    "\n",
    "for d in to_drop:\n",
    "    \n",
    "    try:\n",
    "        df_Att.drop(columns = d, inplace = True)\n",
    "    except:\n",
    "        df_Att\n",
    "\n",
    "    \n",
    "df_Att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save attributes to new csv file\n",
    "df_Att.to_csv('IPO Attributes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996-01-05 00:00:00\n",
      "2018-04-13 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#print min and max ipoDates\n",
    "\n",
    "print(df_Att.ipoDate.min())\n",
    "print(df_Att.ipoDate.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My initial data collection and cleaning phase is complete. I now have a much more managable set of data that's conducive to analysis. A clean pricing table with pricing laid out by day and company in the rows and low, high, opening, closing, and volume in the columns. \n",
    "\n",
    "My attribute table has my stocks filtered out by US company and each stock has 50 pertient meta data points\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Steps:\n",
    "    \n",
    "â€¢ Import MacroEconomic for all months/years relevant to IPO's. I'll start with gdp growth, unemployment, and interest rates I plan to use Pandas DataReader function which has a direct link to https://fred.stlouisfed.org\n",
    "\n",
    "â€¢ I'll need to do some more digging to see where I can find the pre-IPO Revenue, Cash, and EBITDA metrics I mentioned in the steps above to add to my attribute table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import GDP, Fed Funds Rate, Unemployment, Consumer Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas DataReader package has a great way to improt macro-economic data directly from the fred database\n",
    "make sure you have the data reader package installed on your pc: \n",
    "conda install -c anaconda pandas-datareader in the anaconda prompt download for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmur1\\anaconda3\\lib\\site-packages\\pandas_datareader\\compat\\__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n"
     ]
    }
   ],
   "source": [
    "from pandas_datareader.data import DataReader\n",
    "from datetime import date\n",
    "start = date(1990,1,1)\n",
    "\n",
    "#import GDP and calculate quarterly growth\n",
    "GDP = DataReader('GDPC1', 'fred', start )\n",
    "GDP['growth'] = GDP.GDPC1.pct_change(periods = 4)\n",
    "GDP = GDP.reset_index()\n",
    "GDP.columns = ['DATE', 'GDP', 'GDP Growh']\n",
    "GDP['FQ'] = GDP.DATE.apply(FQ)\n",
    "GDP.drop(columns = 'DATE', inplace = True)\n",
    "\n",
    "def FredQ(df, dcolumns, values):\n",
    "    df['FQ'] = df[dcolumns].apply(FQ)\n",
    "    df_Q = pd.DataFrame(df.groupby(['FQ'])[values].mean()).reset_index()\n",
    "    #df_Q.drop(columns = dcolumns, inplace = True)\n",
    "    return df_Q\n",
    "\n",
    "#import Fed Funds Interest rate\n",
    "EFFR = DataReader('FEDFUNDS', 'fred',start).reset_index()\n",
    "EFFRQ = FredQ(EFFR, 'DATE', 'FEDFUNDS')\n",
    "\n",
    "#import unemployment rate\n",
    "UNRATE = DataReader('UNRATE', 'fred',start).reset_index()\n",
    "UNRATEQ = FredQ(UNRATE, 'DATE', 'UNRATE')\n",
    "\n",
    "#import Consumer Sentiment Score\n",
    "CS = DataReader('UMCSENT', 'fred', start).reset_index()\n",
    "CSQ = FredQ(CS, 'DATE', 'UMCSENT')\n",
    "\n",
    "\n",
    "#merge dataframes to one\n",
    "Macro = pd.merge(GDP, EFFRQ, on = 'FQ', how = 'left')\n",
    "Macro = pd.merge(Macro, UNRATEQ, on = 'FQ', how = 'left')\n",
    "Macro = pd.merge(Macro, CSQ, on = 'FQ', how = 'left')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Stock Market and Real Estate Data from Quandl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has a Quandl package but I'm going to use the requests package just to practice .get requests and converting json's into dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import collections\n",
    "\n",
    "def Quandl(url, param_dict, col_names):\n",
    "    \n",
    "    r = requests.get(url, params = param_dict)\n",
    "    json_data = r.json()\n",
    "    df = pd.DataFrame(json_data['dataset']['data'], columns = col_names)\n",
    "    df.DATE = df.DATE.astype('datetime64[ns]')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define quarter based first day of month after QE\n",
    "\n",
    "def FQ_Beg(date):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        if date.month ==4 and date.day == 1:\n",
    "            return '1_' + str(date.year)\n",
    "       \n",
    "        elif date.month== 7 and date.day ==1:\n",
    "            return '2_' + str(date.year)\n",
    "        \n",
    "        elif date.month == 10 and date.day == 1:\n",
    "            return '3_' + str(date.year)\n",
    "        \n",
    "        elif date.month ==1 and date.day == 1:\n",
    "            return '4_'+ str(date.year - 1)\n",
    "        \n",
    "        else:\n",
    "            return 'NA'\n",
    "    except:\n",
    "       \n",
    "        return \"NA\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import S&P 500 P&E Ratios\n",
    "API_KEY = 'pTsozhv5F_xzhfyMkVQi'\n",
    "url = \"https://www.quandl.com/api/v3/datasets/MULTPL/SP500_PE_RATIO_MONTH.json\"\n",
    "p = dict(start_date = '1990-01-01' , api_key = API_KEY)\n",
    "\n",
    "#call my quandl function\n",
    "PE = Quandl(url, p, ['DATE', 'PE_Ratio'])\n",
    "\n",
    "PE['FQ'] = PE['DATE'].apply(FQ)\n",
    "PE_Q = pd.DataFrame(PE.groupby(['FQ'])['PE_Ratio'].mean()).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import S&P Prices and Get Growth Rate by Quarter\n",
    "\n",
    "API_KEY = 'pTsozhv5F_xzhfyMkVQi'\n",
    "url = \"https://www.quandl.com/api/v3/datasets/MULTPL/SP500_REAL_PRICE_MONTH.json\"\n",
    "p = dict(start_date = '1990-01-01' , api_key = API_KEY)\n",
    "\n",
    "#call my quandl function\n",
    "SP = Quandl(url, p, ['DATE', 'SP_Value'])\n",
    "\n",
    "#Use the FQ_Beg function to assign quarters to only the quarter ending dates. Which i've defined as \n",
    "#the first day of the following quarter. The Dataset is reporing monthly S&P data as of the first dat of the month\n",
    "#I only want the quarter end dates and I'm going to drop everything else\n",
    "\n",
    "SP['FQ'] = SP.DATE.apply(FQ_Beg)\n",
    "\n",
    "#Filter out all dates that aren't a quarter end\n",
    "SP_Q = SP[SP['FQ'] != 'NA']\n",
    "SP_Q = SP_Q.sort_values(by = 'DATE', ascending = True)\n",
    "\n",
    "#Calculate percent changes from prior quarter\n",
    "SP_Q['SP500 Growth'] = SP_Q['SP_Value'].pct_change(periods = 4)\n",
    "SP_Q.drop(columns = ['DATE'], inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write function to pull in all states for Zillow Data. Default API only gave option to pull one state at a time\n",
    "\n",
    "def GetZillow(indicator, rType):\n",
    "\n",
    "    API_KEY = 'pTsozhv5F_xzhfyMkVQi'\n",
    "\n",
    "    #pull list of states from quandl's zillow documentation\n",
    "    sturl = \"https://s3.amazonaws.com/quandl-production-static/zillow/state.txt\"\n",
    "    states = pd.read_csv(sturl, delimiter = '|')\n",
    "    \n",
    "    \n",
    "    Zillow = []\n",
    "    Errors = []\n",
    "\n",
    "    #loop through each state and adjust url per the state code\n",
    "    for st in states['CODE']:\n",
    "\n",
    "        quandl = 'S' + str(st) + '_' + indicator + '.json'\n",
    "        url = \"https://www.quandl.com/api/v3/datasets/ZILLOW/\" + quandl\n",
    "        params = dict(api_key = API_KEY, start_date = '1996-01-01')\n",
    "        \n",
    "        #r = requests.get(url, params = params)\n",
    "        #json_data = r.json()\n",
    "       \n",
    "        #if statecode not found drop to error table\n",
    "        try:\n",
    "            df = Quandl(url, p, ['DATE', indicator])\n",
    "            df['statecode'] = st\n",
    "            Zillow.append(df)\n",
    "        except:\n",
    "            Errors.append(st)\n",
    "\n",
    "    #Get lists ready for concatenation\n",
    "    Housing = pd.concat(Zillow)\n",
    "    MissingStates = pd.DataFrame(Errors)\n",
    "\n",
    "    #adjust column names    \n",
    "    Housing.columns = ['Date', indicator, 'CODE']\n",
    "    MissingStates.columns = ['CODE']\n",
    "\n",
    "    #concatenate df's\n",
    "    Housing = pd.merge(Housing, states, on ='CODE', how = 'left')\n",
    "    MissingStates = pd.merge(MissingStates, states, on = 'CODE', how = 'left')\n",
    "\n",
    "          \n",
    "    if rType == 'housing':\n",
    "        return Housing\n",
    "    elif rType == 'errors':\n",
    "        return MissingStates\n",
    "    else:\n",
    "        print('Wrong rType. Needs to be housing or errors')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Foreclosure = GetZillow('HSAFRAL', 'housing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Foreclosure['FQ'] = Foreclosure['Date'].apply(FQ)\n",
    "For_Q = pd.DataFrame(Foreclosure.groupby(['FQ'])['HSAFRAL'].mean()).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull pricing indexes from FMAC data on quandl\n",
    "\n",
    "quandl = \"HPI_ST_SA.json\"\n",
    "url = \"https://www.quandl.com/api/v3/datasets/FMAC/\" + quandl\n",
    "params = dict(api_key = API_KEY)\n",
    "r = requests.get(url, params = params)\n",
    "json_data = r.json()\n",
    "\n",
    "Housing = pd.DataFrame(json_data['dataset']['data']) #convert to df\n",
    "Housing.columns = json_data['dataset']['column_names'] #add column names\n",
    "Housing['Date'] = Housing['Date'].astype('datetime64[ns]') #convert date \n",
    "Housing_Melt = pd.melt(Housing, id_vars = 'Date', var_name = 'State', value_name = 'HPI') #melt data. states were laid out by column\n",
    "Housing_Melt['FQ'] = Housing_Melt['Date'].apply(FQ) # apply quarter\n",
    "Housing_Q = pd.DataFrame(Housing_Melt.groupby(['FQ'])['HPI'].mean()).reset_index() #summarize average by quarter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge to my other Macro dataframe export to clean data folder\n",
    "\n",
    "Macro2 = pd.merge(Macro, PE_Q, on = 'FQ', how = 'left' )\n",
    "Macro2 = pd.merge(Macro2, SP_Q, on = 'FQ', how = 'left')\n",
    "Macro2 = pd.merge(Macro2, For_Q, on = 'FQ', how = 'left' )\n",
    "Macro2 = pd.merge(Macro2, Housing_Q, on = 'FQ', how = 'left' )\n",
    "\n",
    "\n",
    "#export table to my clean data folder\n",
    "os.getcwd()\n",
    "os.chdir('C:\\\\Users\\\\nmur1\\\\Google Drive\\\\Springboard\\\\Capstone 1\\\\CleanData')\n",
    "\n",
    "Macro2.to_csv('MacroEcon.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
